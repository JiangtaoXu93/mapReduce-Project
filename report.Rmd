---
title: "Project Report"
author: "Jiangtao Xu/Yang Xia/Yu Wen"
date: "2017/12/5"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

###<span style = "color:#588bae">Objective</span> 
Given a download dataset, try to make a machine learning model to predict downloads based on several dataset.

###<span style = "color:#588bae">Preparing Data</span>
 - After doing some pre-analysis and disscussion, we decided that we are going to use 4 dataset, joining them together and made our training dataset. The four datasets are: downloads, song_info, jam_to_msd, train_triplets. We figured that we should have all the feature we needed to make a pretty accurate prediction.
 - Aggregated jam_to_msd and train_triplets.
 These 2 features are recorded based on users. If we were to joint them with song_info, we had to first aggreated them on songs. Easy to do in spark but not at all trivial.
 - From 30k to 800k
 First we filted out the corrupted columns and did an inner joint on all 4 of the above dataset, and ended up with a csv file with only 30k rows. Several steps we took to get better:
1) Only doing an inner joint between song_info and downloads, and then left joint the other 2 with the result obtained. And we filled in the null values with 0. This gives us around 400k rows.
2) We found that after filtering out the corrupted columns, only 580w rows remains in song_info, thus resulting only 400k remaining. We tried to filled in the missing value by the techniques as follow:
Based on the assumption of the same artist produced kind of similar songs, we produced an..

This gives us a new dataset with around 680k rows. Still rooms to improve.

3) After carefully looking at the downloads set, we found that artist name and song title are not very clean. So we do the following:
I.   Convert them to lower cases
II.  Remove blank space and all the punctuation.
III. Remove "and", "feat", "vs"
Finally we have a dataset with 800k songs, which covers around 80% of the overall data. For those that were not in our dataset, we think most likely noboday really cares about them. So we'll predict 0 for them, can't be wrong.

###<span style = "color:#588bae">Feature Selection</span>
- Step 1: Pearson correlation. This gives us an intuition of how closely a certain feature is related to the model.

Features                          | RSME
----------------------------------|-------------------------------
familiarity                       | 0.40
Artist_hot                        | 0.84
duration                          |	0.77
loudness                          |	-0.75
song_hotness                      |	0.71
tempo                             |	0.86
mean_price                        |	0.98
Jam_count(filled with 0)          | 0.09
Jam_count(without filling)        | 0.87
taste_count(filled with 0)        | 0.05
taste_count(without filling)      | 0.64

It's interesting to see that taste_count(filled with 0) and Jam_count(filled with 0) almost have no realtion with label. Filling 0 blindly hurts the model accuray. Another intersting fact is that mean price is closely (and positive) related to label, which suggest a higher price implies a higher download, which is very un-expected.

But there're some drawbacks: since it only shows the linear correlation, and there could some high dimensional relation between the feature and the label. 

- Step 2: Pick all the features above(with high correlation), train a random forest model on a randomly selected subset(with non-linearity imposed)

- Step 3: Deleting the model on at each time and recorded the error, which is a pratical way (espeacialy in non-linear system) to determine which feature has a big impact on the model.
At the end we had a table looks like this:

Features                          | RSME
----------------------------------|-------------------------------
All Features                      | 200
without mean_price                | 1809
without taste_count               |	220
without jam_count                 |	197
without familiarity               |	230
without artistHotness             |	356
without duration                  |	256
without loudness                  | 230
without song_hottness             | 221

###<span style = "color:#588bae">Obtaining Dataset</span>
-  General idea: inner joint 2 tables: song_info and donwloads on artist name and song title.
-  Left joint Jam and taste: fill in 0 with the missing values. We think this assumption is valid because if a song never show up in these tables, most likely nobody likes them and nobody has played it. Our model accuracy partly endorse this assumption.

###<span style = "color:#588bae">Implementation</span>
-  We make use of the dataframe in spark to make efficient join.

###<span style = "color:#588bae">Choosing Features</span>
-  Explanation of the features that we chosed.

###<span style = "color:#588bae">Model Selection</span>
-  Trying with different model and the result.


###<span style = "color:#588bae">Machine Learning Implementation</span>
-  Spark ML


###<span style = "color:#588bae">Testing With Current Model</span>

